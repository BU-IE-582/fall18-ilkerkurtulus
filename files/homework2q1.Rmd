---
title: "HW2 Q1"
author: Ilker Kurtulus - IE582 - Fall 2018
---
```{r,echo=FALSE,results="hide"}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

1.Over - Under Analysis

- Part A
```{r eval=TRUE, message=FALSE, warning=FALSE}
library(data.table)
library(anytime)
library(stringr)
library(dplyr)
library(gridExtra)
library(ggplot2)
library(plotly)
library(jpeg)
library(fields)
library(formatR)
```

```{r eval=TRUE}

oo = readRDS("/Users/ilkerkurtulus/Documents/cse-master/ie582/data/hw1/df9b1196-e3cf-4cc7-9159-f236fe738215_odd_details.rds")
oo = data.table(oo)
oo$date = anytime(oo$date)
mm = readRDS("/Users/ilkerkurtulus/Documents/cse-master/ie582/data/hw1/df9b1196-e3cf-4cc7-9159-f236fe738215_matches.rds")
mm = data.table(mm)
mm[, c("leagueId","type"):=NULL]
mm$date = anytime(mm$date)
mm = mm[is.na(mm$score)==FALSE]
mm = mm[, c("home_goal", "away_goal") := tstrsplit(score, ":", fixed=TRUE)]
mm$home_goal = as.numeric(mm$home_goal)
mm$away_goal = as.numeric(mm$away_goal)
mm[, total_goals:=home_goal+away_goal]
mm = mutate(mm, is_over = ifelse(total_goals > 2.5, 1,0))
mm = data.table(mm)
head(mm)
```


Different handicap values mean different events with different probability. So we should not considered them together. Thats why from "ah" betType i will pick totalhandicap = 0 and for "ou" betType lets pick 2.5

While choosing bookmakers we need to care that bookmakers should provide odds of above handicap and bettype. To do that lets print them and choose:

```{r eval=TRUE}
oo[(betType == "ou") & (totalhandicap == "2.5"), .N, by = bookmaker]
```

```{r eval=TRUE}
oo[(betType == "ah") & (totalhandicap == "0"), .N, by = bookmaker]
```

So we can select 5 bookmakers as 1xBet, bet365, Betfair Exchange, Pinnacle and 10Bet

```{r eval=TRUE}
bookmakers = c("1xBet", "bet365", "Betfair Exchange", "Pinnacle","10Bet")
func_1a = function(n_bm){
  df = oo[bookmaker == bookmakers[n_bm]]
  pdf_1 = dcast(df[(betType != "ou") & (betType != "ah" )], matchId + bookmaker ~ betType + oddtype, value.var = c("odd"),  fun.aggregate = mean)
  
  # only choose ah = 0 due to different handicap means different odds, so its not useful to mix different handicaps
  x = df[(betType == "ah") & (totalhandicap == "0")]
  pdf_2 = dcast(x, matchId ~ betType + oddtype, value.var = c("odd"),  fun.aggregate = mean)
  # only choose ou = 2.5 due to different handicap means different odds, so its not useful to mix different handicaps
  x = df[(betType == "ou") & (totalhandicap == "2.5")]
  pdf_3 = dcast(x, matchId ~ betType + oddtype, value.var = c("odd"),  fun.aggregate = mean)
  pdf = na.omit(pdf_1[pdf_2, on = "matchId"][pdf_3, on = "matchId"])
  
  all_df = na.omit(pdf[mm[, c("matchId", "is_over")], on = "matchId"])
  all_df = all_df[, is_over:=as.character(is_over)]
  scaled_df = scale(all_df[, 3:9])
  pca = prcomp(scaled_df, center = TRUE, scale. = TRUE)
  print(summary(pca))
  eigs = pca$sdev^2
  exp_var_ratio = eigs/sum(eigs)
  cum_exp_var_ratio = cumsum(exp_var_ratio)
  
  plot(cum_exp_var_ratio, type = "l", xlab = "# of Principle Components", ylab = "Cumulative Explained Variance")
  title(paste("Cumulative Explained Variance Ratio of PCA for " , bookmakers[n_bm], sep = ""))
  
  all_pca = predict(pca, newdata = scaled_df)
  all_pca2d = all_pca[,1:2]
  all_pca2d = data.table(all_pca2d)
  all_pca2d[,is_over:= all_df$is_over]
  ggplot(all_pca2d, aes(x = PC1, y = PC2, color = is_over)) + geom_point() +   ggtitle(paste("Transformed Data with p = 2 PCA and is_over results",bookmakers[n_bm], sep = " "))
}
```



```{r eval=TRUE}
func_1a(1)
```


```{r eval=TRUE}
func_1a(2)
```


```{r eval=TRUE}
func_1a(3)
```

```{r eval=TRUE}
func_1a(4)
```

```{r eval=TRUE}
func_1a(5)
```

Using first 2 components is easy to visualize however in terms of explaining variance of the data its not beneficial. Yet in our case except bet365 all datatables has higher than 0.70 explained variance ratio so 2d is a good choice to visualization. 

When we look at the scatter plots we cant find a distinction between over/under result. This is caused by selection of p as 2 in PCA and behavior of the data (ie nonlinearity) is not suitable for PCA.



- Part B

Calculation of manhattan and euclidian distances as well as 2D and 3D of them with MDS:

```{r eval=TRUE}
bookmakers = c("1xBet", "bet365", "Betfair Exchange", "Pinnacle","10Bet")
func_1bman= function(n_bm){
  df = oo[bookmaker == bookmakers[n_bm]]
  pdf_1 = dcast(df[(betType != "ou") & (betType != "ah" )], matchId + bookmaker ~ betType + oddtype, value.var = c("odd"),  fun.aggregate = mean)
  
  x = df[(betType == "ah") & (totalhandicap == "0")]
  pdf_2 = dcast(x, matchId ~ betType + oddtype, value.var = c("odd"),  fun.aggregate = mean)
  # only choose ou = 2.5 due to different handicap means different odds, so its not useful to mix different handicaps
  x = df[(betType == "ou") & (totalhandicap == "2.5")]
  pdf_3 = dcast(x, matchId ~ betType + oddtype, value.var = c("odd"),  fun.aggregate = mean)
  
  pdf = na.omit(pdf_1[pdf_2, on = "matchId"][pdf_3, on = "matchId"])
  all_df = na.omit(pdf[mm[, c("matchId", "is_over")], on = "matchId"])
  
  all_df = all_df[, is_over:=as.character(is_over)]
  scaled_df = scale(all_df[, 3:9])
  dist_man = dist(scaled_df, method = "manhattan")
  mds_man2 = data.table(cmdscale(dist_man, eig = TRUE, k = 2)$points)
  mds_man2[,is_over:= all_df$is_over]
  dist_euc = dist(scaled_df, method = "euclidian")
  mds_euc2 = data.table(cmdscale(dist_euc, eig = TRUE, k = 2)$points)
  mds_euc2[,is_over:= all_df$is_over]
  p1 = qplot(data = mds_euc2, V1, V2, color = is_over) + ggtitle( paste("MDS Euclidian and is_over results for",bookmakers[n_bm], sep = " "))
  p2 = qplot(data = mds_man2, V1, V2, color = is_over) + ggtitle( paste("MDS Manhattan and is_over results for",bookmakers[n_bm], sep = " "))
  grid.arrange(p1,p2)
}
```

```{r eval=TRUE}
func_1bman(1)
```
```{r eval=TRUE}
func_1bman(2)
```
```{r eval=TRUE}
func_1bman(3)
```
```{r eval=TRUE}
func_1bman(4)
```
```{r eval=TRUE}
func_1bman(5)
```


Again for MDS it is really hard to say that classes are separated well. Graphs for manhattan and euclidian distances are different indeed due to one of them measures the path while the other calculates shortest path in R^n space. Thats why with manhattan distance makes distance matrix bigger and observations distributed the space in a larger scale like in graph of bet365.

- Part C

Even though we cant observe a clear distinction for MDS and PCA, most probably MDS is a better choice for this data due to handling nonlinearity. When we compare plots on 1a and 1b for each bookmaker plots seem more convex for MDS which explains nonlinearity.



